{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veronhii/datasets/blob/main/COS30019_2023_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPZYB6tPRdIy"
      },
      "source": [
        "# **Setup Libraries / Environment /Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWoElEoPU4-r"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mac9BeUfHu_O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scikitplot as skplt\n",
        "import sklearn\n",
        "\n",
        "from tensorflow import keras\n",
        "from shutil import copyfile\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "from math import sqrt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, ConfusionMatrixDisplay, roc_curve, auc\n",
        "\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import ResNet50, VGG16\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8ODlhTVRvLc"
      },
      "source": [
        "# **Data Preparation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3YsEBaVQqta"
      },
      "source": [
        "## **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LxCow5xmyEp"
      },
      "outputs": [],
      "source": [
        "# Github Repository with its directory in Google Colab\n",
        "repo_url = \"https://github.com/veronhii/datasets\"\n",
        "repo_dir = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY6EAqbiQBGd"
      },
      "outputs": [],
      "source": [
        "# Change directory to /content\n",
        "%cd /content\n",
        "\n",
        "# Clean up the repo\n",
        "!rm -rf {repo_dir}\n",
        "\n",
        "# Git clone the repo\n",
        "!git clone {repo_url}\n",
        "\n",
        "# change directory to /content/datasets\n",
        "# Check repo is up-dated\n",
        "%cd {repo_dir}\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU1imbhzmipp"
      },
      "outputs": [],
      "source": [
        "# Check repo is up-dated\n",
        "%cd {repo_dir}\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_3_IL5ySEfV"
      },
      "source": [
        "## **Directories**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm5ZkVxSMAO2"
      },
      "outputs": [],
      "source": [
        "# Two folders for two classes of data\n",
        "dataset_dir = os.path.join(repo_dir, \"IntroAI\")\n",
        "glasses_dir = os.path.join(dataset_dir, \"glasses\")\n",
        "non_glasses_dir = os.path.join(dataset_dir, \"non_glasses\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TcgQYrSLMMZ"
      },
      "source": [
        "# **Machine Learning Approach**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz53-qPpWUCa"
      },
      "source": [
        "## **Data Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQe5Nb_HmkAZ"
      },
      "outputs": [],
      "source": [
        "# X: images, y: labels\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Append the images and the labels into X and y\n",
        "for folder, label in [(glasses_dir, 0), (non_glasses_dir, 1)]:\n",
        "    for file in os.listdir(folder):\n",
        "        # Locate the file\n",
        "        image_path = os.path.join(folder, file)\n",
        "        # Convert into grayscale and array\n",
        "        image = np.asarray(Image.open(image_path).convert('L'))\n",
        "        # Reshape into 1D array\n",
        "        image = image.reshape(-1)\n",
        "        # Append the \n",
        "        X.append(image)\n",
        "        y.append(label)\n",
        "\n",
        "# Split X and y to train and test (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxOxU9qD_qKe"
      },
      "outputs": [],
      "source": [
        "# Check the shape of the image\n",
        "print(image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZst9gb9YyqE"
      },
      "source": [
        "## **Classifiers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw1OVxfhwL-4"
      },
      "outputs": [],
      "source": [
        "# Classifiers to be used\n",
        "def RandomForest():\n",
        "    rfclassifier = RandomForestClassifier(random_state=42, max_depth=2, min_samples_split=10, n_jobs=-1, n_estimators=10, class_weight=\"balanced\")\n",
        "    return rfclassifier\n",
        "\n",
        "def DecisionTree():\n",
        "    dtclassifier = DecisionTreeClassifier(random_state=42, max_features=1000, min_samples_leaf=100, min_samples_split=100, class_weight=\"balanced\")\n",
        "    return dtclassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akzKdgCYXzoR"
      },
      "outputs": [],
      "source": [
        "rfclassifier = RandomForest()\n",
        "dtclassifier = DecisionTree()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6PO-dFRYcpG"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjn2aSYQwPvO"
      },
      "outputs": [],
      "source": [
        "print(rfclassifier.fit(X_train, y_train))\n",
        "print(dtclassifier.fit(X_train, y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save Weight**"
      ],
      "metadata": {
        "id": "q30mc2B4lgqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# save\n",
        "joblib.dump(rfclassifier, \"/content/datasets/my_random_forest.joblib\")\n",
        "joblib.dump(dtclassifier, \"/content/datasets/my_decision_tree.joblib\")\n"
      ],
      "metadata": {
        "id": "oPoLefW_lg0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHX7K6mIYuf3"
      },
      "source": [
        "## **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIb1g0zEwRWW"
      },
      "outputs": [],
      "source": [
        "score_1 = rfclassifier.score(X_test, y_test)\n",
        "y_pred_1 = rfclassifier.predict(X_test)\n",
        "\n",
        "score_2 = dtclassifier.score(X_test, y_test)\n",
        "y_pred_2 = dtclassifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvgLAwN0GN-8"
      },
      "source": [
        "## **Evaluation (Scores)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier - Score on test data\n",
        "print(\"Classifier 1: Random Forest\")\n",
        "print(\"Score:\",score_1)\n",
        "\n",
        "# Decision Tree Classifier - Score on test data\n",
        "print(\"\\n\\nClassifier 2: Decision Tree\")\n",
        "print(\"Score:\",score_2)"
      ],
      "metadata": {
        "id": "M8Ev91W9Psjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2rP3RreIHTB"
      },
      "outputs": [],
      "source": [
        "# Evaluation on the scores for Random Forest Classifier\n",
        "print('Classifier 1: Random Forest')\n",
        "mse = mean_squared_error(y_test, y_pred_1)\n",
        "print('Mean Square Error:', mse)\n",
        "rmse = sqrt(mse)\n",
        "print('Root Mean Square Error:', rmse)\n",
        "accuracy = accuracy_score(y_test, y_pred_1)\n",
        "print('Accuracy:', accuracy)\n",
        "precision = precision_score(y_test, y_pred_1)\n",
        "print('Precision:', precision)\n",
        "recall = recall_score(y_test, y_pred_1)\n",
        "print('Recall:', recall)\n",
        "f1 = f1_score(y_test, y_pred_1)\n",
        "print('F1 score:', f1)\n",
        "\n",
        "# Evaluation on the scores for Decision Trees Classifier\n",
        "print('\\n\\nClassifier 2: Decision Trees')\n",
        "mse = mean_squared_error(y_test, y_pred_2)\n",
        "print('Mean Square Error:', mse)\n",
        "rmse = sqrt(mse)\n",
        "print('Root Mean Square Error:', rmse)\n",
        "accuracy = accuracy_score(y_test, y_pred_2)\n",
        "print('Accuracy:', accuracy)\n",
        "precision = precision_score(y_test, y_pred_2)\n",
        "print('Precision:', precision)\n",
        "recall = recall_score(y_test, y_pred_2)\n",
        "print('Recall:', recall)\n",
        "f1 = f1_score(y_test, y_pred_2)\n",
        "print('F1 score:', f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-gRd5D0Qdf4"
      },
      "source": [
        "## **Visualisation on Graphs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTJD5mzsQnf7"
      },
      "outputs": [],
      "source": [
        "# Precision-Recall-Curve (Random Forest Classifier)\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_1)\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (Random Forest Classifier)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# Precision-Recall-Curve (Decision Tree Classifier)\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_2)\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (Decision Tree Classifier)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y_sEn31GRg7"
      },
      "outputs": [],
      "source": [
        "# ROC curve (Random Forest Classifier)\n",
        "# Get the predicted probabilities for the test set\n",
        "y_prob_1 = rfclassifier.predict_proba(X_test)[:, 1]\n",
        "# Compute the false positive rate, true positive rate, and thresholds\n",
        "fpr1, tpr1, thresholds = roc_curve(y_test, y_prob_1)\n",
        "# Compute the area under the ROC curve\n",
        "roc_auc = auc(fpr1, tpr1)\n",
        "\n",
        "plt.plot(fpr1, tpr1, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic for Random Forest Classifier')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# ROC curve (Decision Trees Classifier)\n",
        "# Get the predicted probabilities for the test set\n",
        "y_prob_2 = dtclassifier.predict_proba(X_test)[:, 1]\n",
        "# Compute the false positive rate, true positive rate, and thresholds\n",
        "fpr2, tpr2, thresholds = roc_curve(y_test, y_prob_2)\n",
        "# Compute the area under the ROC curve\n",
        "roc_auc = auc(fpr2, tpr2)\n",
        "\n",
        "plt.plot(fpr2, tpr2, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic for Decision Trees Classifier')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P1Xrt4Jwg6f"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix (Random Forest Classifier)\n",
        "f,ax=plt.subplots(1,1,figsize=(8,8))\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred_1, normalize='true',ax=ax)\n",
        "plt.title('Confusion Matrix (Random Forest Classifier)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# Confusion Matrix (Decision Trees Classifier)\n",
        "f,ax=plt.subplots(1,1,figsize=(8,8))\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred_2, normalize='true',ax=ax)\n",
        "plt.title('Confusion Matrix (Decision Trees Classifier)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZP-iaCULSc4"
      },
      "source": [
        "# **Deep Learning Approach**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygFEJlxaHlu4"
      },
      "outputs": [],
      "source": [
        "train_percent = 0.7\n",
        "val_percent = 0.15\n",
        "test_percent = 0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMzSrjv5GPtJ"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "val_dir = os.path.join(dataset_dir, 'val')\n",
        "test_dir = os.path.join(dataset_dir, 'test')\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "    os.mkdir(train_dir)\n",
        "if not os.path.exists(val_dir):\n",
        "    os.mkdir(val_dir)\n",
        "if not os.path.exists(test_dir):\n",
        "    os.mkdir(test_dir)\n",
        "\n",
        "for folders in [\"train\", \"val\", \"test\"]:\n",
        "    glasses_dir = os.path.join(dataset_dir, folders, \"glasses\")\n",
        "    non_glasses_dir = os.path.join(dataset_dir, folders, \"non_glasses\")\n",
        "\n",
        "    if not os.path.exists(glasses_dir):\n",
        "        os.mkdir(glasses_dir)\n",
        "    if not os.path.exists(non_glasses_dir):\n",
        "        os.mkdir(non_glasses_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB8lgX17HtX2"
      },
      "outputs": [],
      "source": [
        "for classes in [\"glasses\",\"non_glasses\"]:\n",
        "    # get a list of all the image files in the animal folder\n",
        "    folder = os.path.join(dataset_dir, classes)\n",
        "    files = os.listdir(folder)\n",
        "    random.shuffle(files)\n",
        "    \n",
        "    # split the files into train, val, and test sets\n",
        "    train_end = int(len(files) * train_percent)\n",
        "    val_end = int(len(files) * (train_percent + val_percent))\n",
        "    train_files = files[:train_end]\n",
        "    val_files = files[train_end:val_end]\n",
        "    test_files = files[val_end:]\n",
        "    \n",
        "    # copy the files into the corresponding train, val, and test folders\n",
        "    for file in train_files:\n",
        "        copyfile(os.path.join(folder, file), os.path.join(dataset_dir, \"train\", classes, file))\n",
        "    for file in val_files:\n",
        "        copyfile(os.path.join(folder, file), os.path.join(dataset_dir, \"val\", classes, file))\n",
        "    for file in test_files:\n",
        "        copyfile(os.path.join(folder, file), os.path.join(dataset_dir, \"test\", classes, file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21M5DL9_M02J"
      },
      "outputs": [],
      "source": [
        "len(os.listdir(os.path.join(dataset_dir, \"train\",\"non_glasses\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfucZ0bhEUB9"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='binary',\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_data = val_test_datagen.flow_from_directory(\n",
        "    directory=val_dir,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='binary',\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_data = val_test_datagen.flow_from_directory(\n",
        "    directory=test_dir,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='binary',\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices = test_data.class_indices\n",
        "print(class_indices)"
      ],
      "metadata": {
        "id": "cRaIGPGK9_1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZOBsYsjltfT"
      },
      "outputs": [],
      "source": [
        "def resnet50():\n",
        "  pretrained_model = ResNet50(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\", pooling='max')\n",
        "  for layer in pretrained_model.layers[:-5]:\n",
        "      layer.trainable = False\n",
        "  return pretrained_model\n",
        "  \n",
        "def vgg16():\n",
        "  pretrained_model = VGG16(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\", pooling='max')\n",
        "  for layer in pretrained_model.layers[:-5]:\n",
        "      layer.trainable = False\n",
        "  return pretrained_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0sBh-c-ShXC"
      },
      "outputs": [],
      "source": [
        "def create_model(pretrained_model):\n",
        "  model = Sequential()\n",
        "  model.add(pretrained_model)\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS9E5A6qTKpV"
      },
      "outputs": [],
      "source": [
        "pretrained_model_resnet50 = resnet50()\n",
        "pretrained_model_vgg16 = vgg16()\n",
        "\n",
        "model1 = create_model(pretrained_model_resnet50)\n",
        "model2 = create_model(pretrained_model_vgg16)\n",
        "\n",
        "model1.summary()\n",
        "print(\"\\n\\n\")\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOHanG0rPW3h"
      },
      "outputs": [],
      "source": [
        "model1.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model2.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model1.fit(train_data,\n",
        "          validation_data = val_data,\n",
        "          steps_per_epoch = train_data.n//train_data.batch_size,\n",
        "          validation_steps = val_data.n//val_data.batch_size,\n",
        "          epochs=10)\n",
        "\n",
        "history2 = model2.fit(train_data,\n",
        "          validation_data = val_data,\n",
        "          steps_per_epoch = train_data.n//train_data.batch_size,\n",
        "          validation_steps = val_data.n//val_data.batch_size,\n",
        "          epochs=10)"
      ],
      "metadata": {
        "id": "Dum7Zo3di99n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5iOe1MrErCV"
      },
      "outputs": [],
      "source": [
        "# Save the model \n",
        "# Choose one name to save according to the architecture used\n",
        "model1.save(\"Resnet50_GlassesVsNonglasses.h5\")\n",
        "model2.save(\"VGG16_GlassesVsNonglasses.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"Resnet50_GlassesVsNonglasses.h5\")\n",
        "files.download(\"VGG16_GlassesVsNonglasses.h5\")"
      ],
      "metadata": {
        "id": "Kd79uprnbfJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVheCOsvNuhQ"
      },
      "outputs": [],
      "source": [
        "path_saved_model = \"/content/datasets/\"\n",
        "model1_name = \"Resnet50_GlassesVsNonglasses.h5\"\n",
        "model2_name = \"VGG16_GlassesVsNonglasses.h5\"\n",
        "\n",
        "model1 = load_model(os.path.join(path_saved_model, model1_name))\n",
        "model2 = load_model(os.path.join(path_saved_model, model2_name))\n",
        "\n",
        "score = model1.evaluate(val_data)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "score = model2.evaluate(val_data)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj5jYRDwN7rJ"
      },
      "outputs": [],
      "source": [
        "predict_1 = model1.predict(test_data)\n",
        "predict_2 = model2.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OQtEEneN8z4"
      },
      "outputs": [],
      "source": [
        "y_classes_1 = np.where(predict_1 > 0.5, 1, 0)\n",
        "y_classes_2 = np.where(predict_2 > 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check repo is up-dated\n",
        "%cd {repo_dir}\n",
        "!git pull"
      ],
      "metadata": {
        "id": "Zq3bLk_uWzFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation (Scores)**"
      ],
      "metadata": {
        "id": "MhSNsiVuX3kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the true labels from the ImageDataGenerator\n",
        "test_labels = test_data.labels\n",
        "\n",
        "# Evaluation on the scores for VGG16\n",
        "print('Model 1: ResNet50')\n",
        "mse = mean_squared_error(test_labels, y_classes_1)\n",
        "print('Mean Square Error:', mse)\n",
        "rmse = sqrt(mse)\n",
        "print('Root Mean Square Error:', rmse)\n",
        "accuracy = accuracy_score(test_labels, y_classes_1)\n",
        "print('Accuracy:', accuracy)\n",
        "precision = precision_score(test_labels, y_classes_1, average='macro', zero_division=1)\n",
        "print('Precision:', precision)\n",
        "recall = recall_score(test_labels, y_classes_1, average='macro')\n",
        "print('Recall:', recall)\n",
        "f1 = f1_score(test_labels, y_classes_1, average='macro')\n",
        "print('F1 score:', f1)\n",
        "\n",
        "# Evaluation on the scores for VGG16\n",
        "print('\\n\\nModel 2: VGG16')\n",
        "mse = mean_squared_error(test_labels, y_classes_2)\n",
        "print('Mean Square Error:', mse)\n",
        "rmse = sqrt(mse)\n",
        "print('Root Mean Square Error:', rmse)\n",
        "accuracy = accuracy_score(test_labels, y_classes_2)\n",
        "print('Accuracy:', accuracy)\n",
        "precision = precision_score(test_labels, y_classes_2, average='macro', zero_division=1)\n",
        "print('Precision:', precision)\n",
        "recall = recall_score(test_labels, y_classes_2, average='macro')\n",
        "print('Recall:', recall)\n",
        "f1 = f1_score(test_labels, y_classes_2, average='macro')\n",
        "print('F1 score:', f1)"
      ],
      "metadata": {
        "id": "2zgRHeoAYRoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualisations on Graph**"
      ],
      "metadata": {
        "id": "Grb0yrWlYGk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision-Recall-Curve (Resnet50)\n",
        "precision, recall, thresholds = precision_recall_curve(test_labels, y_classes_1)\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (Resnet50)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# Precision-Recall-Curve (VGG16)\n",
        "precision, recall, thresholds = precision_recall_curve(test_labels, y_classes_2)\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (VGG16)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "alA4Xb-5ZOcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix (Resnet50)\n",
        "f,ax=plt.subplots(1,1,figsize=(8,8))\n",
        "skplt.metrics.plot_confusion_matrix(test_labels, y_classes_1, normalize='true',ax=ax)\n",
        "plt.title('Confusion Matrix (Resnet50)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# Confusion Matrix (VGG16)\n",
        "f,ax=plt.subplots(1,1,figsize=(8,8))\n",
        "skplt.metrics.plot_confusion_matrix(test_labels, y_classes_2, normalize='true',ax=ax)\n",
        "plt.title('Confusion Matrix (VGG16)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "462-bN_BdDTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LIVE CAMERA FEED FACIAL DETECTION**"
      ],
      "metadata": {
        "id": "BH9vTkXQB3w7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model \n",
        "from keras.utils import img_to_array\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pl\n",
        "import joblib\n",
        "\n",
        "\n",
        "path_saved_model = '/content/datasets/'\n",
        "model1_name = 'Resnet50_GlassesVsNonglasses.h5'\n",
        "model2_name = 'VGG16_GlassesVsNonglasses.h5'\n",
        "\n",
        "model1 = load_model(os.path.join(path_saved_model, model1_name))\n",
        "model2 = load_model(os.path.join(path_saved_model, model2_name))\n",
        "\n",
        "\n",
        "loaded_rf = RandomForestClassifier()\n",
        "loaded_dt = DecisionTreeClassifier()\n",
        "# # load\n",
        "loaded_rf = joblib.load(\"/content/datasets/my_random_forest.joblib\")\n",
        "loaded_dt = joblib.load(\"/content/datasets/my_decision_tree.joblib\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3UFg1GvB-VGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes\n",
        "     \n",
        "     \n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"Status:\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '' +\n",
        "          'When finished, click here or on the video to stop this demo';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "LXd1PVRK-VkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from google.colab.patches import cv2_imshow\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "\n",
        "\n",
        "    # ========================================machine learning\n",
        "\n",
        "    # js_reply = video_frame(label_html, bbox)\n",
        "    # if not js_reply:\n",
        "    #     break\n",
        "\n",
        "    # # convert JS response to OpenCV Image\n",
        "    # img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # # Convert into grayscale\n",
        "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # resized_img = cv2.resize(gray, (1024, 1024))\n",
        "      \n",
        "    # # for machine learning approach\n",
        "    # resized_img = resized_img.reshape(-1)\n",
        "\n",
        "    # prediction = loaded_rf.predict([resized_img])\n",
        "    # # prediction = model2.predict(img_preprocessed, verbose=0)\n",
        "\n",
        "    # if(prediction == 0):\n",
        "    #   predicted_class = \"Glasses\"\n",
        "    # else:\n",
        "    #   predicted_class = \"Non Glasses\"\n",
        "\n",
        "    \n",
        "    # bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # # creating a image object \n",
        "    # img = Image.fromarray(bbox_array)\n",
        "    # draw = ImageDraw.Draw(img) \n",
        "      \n",
        "    # # specified font size\n",
        "    # font = ImageFont.truetype('/content/datasets/arial.ttf', 50) \n",
        "      \n",
        "    # text = predicted_class\n",
        "      \n",
        "    # text_color = (255, 0, 0)\n",
        "\n",
        "    # # drawing text size\n",
        "    # draw.text((5, 5), text, font = font, fill=text_color, align =\"left\") \n",
        "\n",
        "    # bbox = np.array(img) \n",
        "    # # convert overlay of bbox into bytes\n",
        "    # bbox_bytes = bbox_to_bytes(bbox)\n",
        "    # # update bbox so the next frame gets a new overlay\n",
        "    # bbox = bbox_bytes\n",
        "\n",
        "\n",
        "\n",
        "    # ========================================deep learning\n",
        "\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    resized_img = cv2.resize(img, (224, 224))\n",
        "    # Image.fromarray(resized_img).show()\n",
        "    img_array =image.img_to_array(resized_img)\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "    img_preprocessed = preprocess_input(img_batch)\n",
        "    prediction = model1.predict(img_preprocessed, verbose=0)\n",
        "\n",
        "    if(prediction[0][0] > 0.5):\n",
        "      predicted_class = \"Glasses\"\n",
        "    else:\n",
        "      predicted_class = \"Non Glasses\"\n",
        "\n",
        "    \n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # creating a image object \n",
        "    img = Image.fromarray(bbox_array)\n",
        "    draw = ImageDraw.Draw(img) \n",
        "      \n",
        "    # specified font size\n",
        "    font = ImageFont.truetype('/content/datasets/arial.ttf', 50) \n",
        "      \n",
        "    text = predicted_class + str(prediction[0][0])\n",
        "      \n",
        "    text_color = (255, 0, 0)\n",
        "\n",
        "    # drawing text size\n",
        "    draw.text((5, 5), text, font = font, fill=text_color, align =\"left\") \n",
        "\n",
        "    bbox = np.array(img) \n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox)\n",
        "    # update bbox so the next frame gets a new overlay\n",
        "    bbox = bbox_bytes\n",
        "    \n"
      ],
      "metadata": {
        "id": "MwxHuggn-VpU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CPZYB6tPRdIy",
        "a8ODlhTVRvLc",
        "V3YsEBaVQqta",
        "y_3_IL5ySEfV",
        "Xz53-qPpWUCa",
        "IZst9gb9YyqE",
        "dHX7K6mIYuf3",
        "lvgLAwN0GN-8",
        "8-gRd5D0Qdf4",
        "hZP-iaCULSc4",
        "MhSNsiVuX3kG",
        "Grb0yrWlYGk0"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}